
防范人工智能风险

眼下，不少地区布局人工智能领域，推动新一代人工智能健康发展。人工智能正广泛应用于金融、医疗、交通、制造业等领域，成为推动经济社会发展的重要引擎。不过，正如“硬币的两面”，人工智能在带来高效便利的同时，也可能引发隐患和危机。对此，要增强风险防范意识，以富有前瞻性的有力举措，管控好人工智能技术可能带来的各类风险。
从目前情况看，人工智能可能引发的风险主要包括如下几方面。从技术角度看，人工智能本身的技术逻辑及其应用过程存在模糊性，可能引发数据、算法和模型风险。如果数据的数量或质量出现问题，可能无法反映现实世界的真实情况；算法“黑箱”和不可解释性问题，在容错率低的行业，甚至可能造成不可挽回的安全隐患；另外，模型完整性攻击，又称“对抗攻击”，即干扰模型的学习和预测过程，可能误导人工智能“指鹿为马”。
##paidbegin##从法律伦理道德层面看，人工智能的广泛应用可能衍生技术滥用、数据安全、隐私保护等方面的安全挑战，给公民的信息安全、财产安全甚至生命安全造成威胁。例如，恶意运用人工智能伪造虚假人脸，危害个人金融安全；在采集、使用和分析海量数据的过程中，发生隐私泄露、数据篡改、真假难辨等隐患；智能推送算法还引发了“信息茧房”、极化现象以及大数据“杀熟”现象；人工智能运用到无人驾驶、医疗诊断等领域，可能引发权责边界模糊问题；人工智能文本数据挖掘可能产生的知识产权争议问题等，都是引发法律和伦理道德风险的典型案例。
人工智能所带来的风险并非单一的、直线的，而是多种风险交织交融的。这就要求我们系统全面地认识人工智能，提早开展人工智能风险治理。
一方面，要推动技术进步。针对人工智能的模型、算法、数据、隐私和应用等风险和安全威胁，加强安全保护基础理论研究和前沿安全技术研究，推动关键技术应用，构建人工智能安全治理技术体系，是有效管控人工智能风险的关键。这是一个需要各个层面通力合作、集智攻关的长期工作。在社会层面，网络安全龙头企业可以牵头组建创新联合体，在开展理论研究和技术攻关的同时，加强数字安全人才培养，规范技术标准、测试标准和应用规范，增进数字安全的国内外交流合作，以技术创新引领人工智能安全治理。
另一方面，还要不断加强管理。不久前，我国《生成式人工智能服务管理暂行办法》颁布施行，国家层面的人工智能法草案在提速，各种专门立法也在积极探索。我国正以高度负责任的态度参与全球人工智能治理，在贡献中国智慧的同时抢占全球人工智能治理话语权。在实践中，对发展中的问题应及时回应，充分发挥处于实践前沿的企业、行业组织的作用。主管单位要与企业、行业组织、科研机构以及公众建立广泛的合作和沟通机制，以有效引导企业和行业组织进行自我监管，发挥科研机构协助监督和识别潜在风险的作用，帮助公众提升人工智能风险防范意识。

##paidend##
